{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939f6cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pre-trained model and feature extractor\n",
    "model_name = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "])\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_images_from_folder(folder_path):\n",
    "    image_paths = []\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                image = Image.open(path).convert('RGB')\n",
    "                image = preprocess(image)\n",
    "                images.append(image)\n",
    "                image_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {path}: {e}\")\n",
    "    return image_paths, images\n",
    "\n",
    "gallery_folder = \"Data_example/test/gallery\"\n",
    "query_folder   = \"Data_example/test/query\"\n",
    "\n",
    "gallery_paths, gallery_images = load_images_from_folder(gallery_folder)\n",
    "query_paths, query_images     = load_images_from_folder(query_folder)\n",
    "\n",
    "# Extract embeddings\n",
    "def extract_embeddings(images):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for image in images:\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "            outputs = model(image)\n",
    "            embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "            embeddings.append(embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "gallery_embeddings = extract_embeddings(gallery_images)\n",
    "query_embeddings   = extract_embeddings(query_images)\n",
    "\n",
    "# Normalize\n",
    "gallery_embeddings = gallery_embeddings / np.linalg.norm(gallery_embeddings, axis=1, keepdims=True)\n",
    "query_embeddings   = query_embeddings / np.linalg.norm(query_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# FAISS index\n",
    "dimension = gallery_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(gallery_embeddings)\n",
    "\n",
    "# Similarity search\n",
    "k = 5\n",
    "distances, indices = index.search(query_embeddings, k)\n",
    "\n",
    "# Prepare submission format\n",
    "results = []\n",
    "for i, query_path in enumerate(query_paths):\n",
    "    top_k_paths = [gallery_paths[idx] for idx in indices[i]]\n",
    "    results.append({\n",
    "        \"filename\": query_path,\n",
    "        \"gallery_images\": top_k_paths\n",
    "    })\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"submission4.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved submission JSON to 'submission_vit_faiss.json'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
